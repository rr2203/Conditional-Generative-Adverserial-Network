{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzAVmJSHzfU-"
      },
      "source": [
        "# Goal: Explore Conditional GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eciPDnHzfVA"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVvchCm7zfVA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4zOYqG1zfVC"
      },
      "source": [
        "## MNIST Data\n",
        "\n",
        "For this demo, we will be using the MNIST data set. We can apply GANs to other datasets but the training process takes much longer. Our goal will be to supply random noise and a class label (e.g. a digit between 0 and 9) to the generator and produce an image of that particular digit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9yY91PEzfVC"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5], std=[0.5])])\n",
        "\n",
        "data = datasets.MNIST(root='../data/', train=True, transform=transform, download=True)\n",
        "batch_size = 64\n",
        "data_loader = DataLoader(dataset=data, batch_size=batch_size, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdtmNJNJzfVC"
      },
      "source": [
        "We drop the last batch in our training set. We do this so that each batch passed into our networks is always of size 64 (since the number of training samples isn't divisible by 64). Also take a careful look at our normalization factors ($\\mu, \\sigma=0.5$). By using these normalization factors, we constrain each pixel value in our image to within $[-1, 1]$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN2ZkVg0zfVC",
        "outputId": "2e653fca-3503-41af-de3e-5f0302a9ab83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min pixel value: tensor(-1.)\n",
            "max pixel value: tensor(1.)\n",
            "avg pixel value: tensor(-0.7313)\n"
          ]
        }
      ],
      "source": [
        "images, _ = next(iter(data_loader))\n",
        "print(\"min pixel value:\", images.min())\n",
        "print(\"max pixel value:\", images.max())\n",
        "print(\"avg pixel value:\", images.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqQ9ss8qzfVC"
      },
      "source": [
        "This normalization strategy will come in handy for our generator: the last-layer activation function will be `tanh` which is also constrained to be within $[-1,1]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LILMNVm2zfVC"
      },
      "source": [
        "## Building $G$ and $D$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QCinLu5zfVD"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_size=100, num_classes=10, image_size=28*28):\n",
        "        super(Generator, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(noise_size+num_classes, 128), # [noise input, one-hot label] concatenated \n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, image_size), # flattened image\n",
        "            nn.Tanh() # min value: -1, max value: 1\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, c):\n",
        "        x, c = x.view(x.size(0), -1), c.view(c.size(0), -1).float()\n",
        "        v = torch.cat((x, c), 1) # v: [noise input, one-hot label] concatenated vector\n",
        "        y_ = self.network(v)\n",
        "        y_ = y_.view(x.size(0), 1, 28, 28) # flattened image\n",
        "        return y_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMW4EfqFzfVD"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_size=28*28, num_classes=10, num_output=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(image_size+num_classes, 512),   # [flattened image, one-hot label] concatenated vector\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, num_output),\n",
        "            nn.Sigmoid(), #min value: 0, max value: 1 -> great for probabilities!\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, c):        \n",
        "        x, c = x.view(x.size(0), -1), c.view(c.size(0), -1).float()\n",
        "        v = torch.cat((x, c), 1) # v: [flattened image, one-hot label] concatenated vector\n",
        "        y_ = self.network(v)\n",
        "        return y_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kmGj_V8zfVD"
      },
      "source": [
        "## Training Setup\n",
        "\n",
        "Now, we're ready to instantiate our models, hyperparameters, and optimizers. Since the task is so easy for MNIST, we will train for only 10 epochs. We will update the generator and discriminator in every step but often one can be trained more frequently than the other. We need to instantiate two optimizers: one for each newtork. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YeHoiREzfVD",
        "outputId": "1d991c01-beae-4d20-b165-ae4dd68d01a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", DEVICE)\n",
        "\n",
        "D = Discriminator().to(DEVICE)\n",
        "G = Generator().to(DEVICE)\n",
        "\n",
        "max_epoch = 10\n",
        "step = 0\n",
        "n_noise = 100 # size of noise vector\n",
        "\n",
        "criterion = nn.BCELoss() # binary-cross entropy loss\n",
        "D_opt = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "G_opt = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# We will denote real images as having a label 1 and fake images as having a label of 0\n",
        "# This is why we needed to drop the last batch of the data loader\n",
        "D_labels = torch.ones([batch_size, 1]).to(DEVICE) # Discriminator label: real image\n",
        "D_fakes = torch.zeros([batch_size, 1]).to(DEVICE) # Discriminator Label: fake image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVL9pJxBzfVD"
      },
      "source": [
        "## Training\n",
        "Now, let's train both networks. Remember that we will have two loss terms for the discriminator and one loss term for the generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e5vZlqszfVD",
        "outputId": "864e528b-e32b-4ea7-983b-c69e5b9abb32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0/10, Step: 0, D Loss: 1.383345365524292, G Loss: -0.6775472164154053\n",
            "Epoch: 0/10, Step: 500, D Loss: 1.3113811016082764, G Loss: -0.5134172439575195\n",
            "Epoch: 1/10, Step: 1000, D Loss: 1.415831446647644, G Loss: -0.26758670806884766\n",
            "Epoch: 1/10, Step: 1500, D Loss: 0.8949247002601624, G Loss: -0.5527048110961914\n",
            "Epoch: 2/10, Step: 2000, D Loss: 1.3046650886535645, G Loss: -0.5584967732429504\n",
            "Epoch: 2/10, Step: 2500, D Loss: 1.239891767501831, G Loss: -0.45827552676200867\n",
            "Epoch: 3/10, Step: 3000, D Loss: 1.4110296964645386, G Loss: -0.5067005157470703\n",
            "Epoch: 3/10, Step: 3500, D Loss: 1.1709760427474976, G Loss: -0.5282682180404663\n",
            "Epoch: 4/10, Step: 4000, D Loss: 1.213775396347046, G Loss: -0.6103003621101379\n",
            "Epoch: 4/10, Step: 4500, D Loss: 1.258767008781433, G Loss: -0.5418068766593933\n",
            "Epoch: 5/10, Step: 5000, D Loss: 1.3338922262191772, G Loss: -0.5702112913131714\n",
            "Epoch: 5/10, Step: 5500, D Loss: 1.3585987091064453, G Loss: -0.7409588098526001\n",
            "Epoch: 6/10, Step: 6000, D Loss: 1.264848232269287, G Loss: -0.5360286831855774\n",
            "Epoch: 6/10, Step: 6500, D Loss: 1.275842547416687, G Loss: -0.6303281188011169\n",
            "Epoch: 7/10, Step: 7000, D Loss: 1.3130686283111572, G Loss: -0.5940064191818237\n",
            "Epoch: 8/10, Step: 7500, D Loss: 1.4376938343048096, G Loss: -0.366084486246109\n",
            "Epoch: 8/10, Step: 8000, D Loss: 1.3685734272003174, G Loss: -0.5564680099487305\n",
            "Epoch: 9/10, Step: 8500, D Loss: 1.3512009382247925, G Loss: -0.4755713939666748\n",
            "Epoch: 9/10, Step: 9000, D Loss: 1.3180818557739258, G Loss: -0.5924389362335205\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(max_epoch):\n",
        "    for idx, (images, labels) in enumerate(data_loader):\n",
        "        x = images.to(DEVICE)\n",
        "        y = labels.to(DEVICE)\n",
        "        y = F.one_hot(y, num_classes=10)\n",
        "        \n",
        "\n",
        "        # Discriminator - Real Images\n",
        "        x_outputs = D(x, y)                              # pass images and class labels to discriminator\n",
        "        D_x_loss = criterion(x_outputs, D_labels)        # Discriminator loss for real images\n",
        "        \n",
        "        # Discriminator - Fake Images\n",
        "        z = torch.randn(batch_size, n_noise).to(DEVICE)  # sample from standard dist.\n",
        "        z_ = G(z,y)                                      # pass noise and class label to generator\n",
        "        z_outputs = D(z_, y)                             # pass fake images and label to discriminator\n",
        "        D_z_loss = criterion(z_outputs, D_fakes)         # Discriminator loss for fake images\n",
        "        \n",
        "        D_loss = D_x_loss + D_z_loss                     # Total Discriminator loss\n",
        "        \n",
        "        # Optimize the Discriminator\n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_opt.step()\n",
        "        \n",
        "        # Generator - Fake Images\n",
        "        z = torch.randn(batch_size, n_noise).to(DEVICE)  # sample from standard dist.\n",
        "        z_ = G(z,y)                                      # pass noise and class label to generator\n",
        "        z_outputs = D(z_, y)                             # pass fake images and label to discriminator\n",
        "        G_loss = -1 * criterion(z_outputs, D_fakes)      # Generator loss is negative disciminator fake-loss\n",
        "\n",
        "        # Optimize the Generator\n",
        "        G.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_opt.step()\n",
        "        \n",
        "        if step % 500 == 0:\n",
        "            print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, max_epoch, step, D_loss.item(), G_loss.item()))\n",
        "        step += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or3xZN7nzfVD"
      },
      "source": [
        "## Generate Samples (Conditioned on the class label!)\n",
        "Let's generate a few samples now! Don't forget to set the generator to `eval` mode. We have layers in our generator that work differently during training and inference time (which one?). Let's set the class label to 8 and generate a few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT-itkYOzfVE",
        "outputId": "9ca0a12a-9150-4c37-8b31-f2de2f596100"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7cb95aa760>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAO80lEQVR4nO3dfYxc1X3G8efZZQ34DbMhOC64YGMT7KTFTrakKpRQ0UbYjWpoJILTEBfRbqJCFNSoCiKVQFWboigJpVET1Ql2DCJOkYyDW1nFjotwaYVhTfxuwluwsLXYSd3IYGPM7v76x17SDew9s5537/l+pNXM3N/cmR8DD/fOPffOcUQIwPjX0eoGADQHYQcyQdiBTBB2IBOEHcjEac18s86Jk6JrWndpfUL/0SZ2A4w/x3VUJ+JNj1arKey2r5F0r6ROSd+NiLtTz++a1q0Lev+ytP7rf/PftbQDZG9LbCqtVb0bb7tT0j9JWiRpvqSltudX+3oAGquW7+yXSXohIl6KiBOSfiBpSX3aAlBvtYT9PEmvjHi8v1j2K2z32u6z3Td4jO/kQKs0/Gh8RCyPiJ6I6OmcOKnRbwegRC1hPyBp5ojH5xfLALShWsL+tKS5tmfZniDpBknr6tMWgHqreugtIgZs3yrpUQ0Pva2IiN2pdSb0H2V4DWiRmsbZI2K9pPV16gVAA3G6LJAJwg5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYIO5CJpv6UdCN9Yu+hZH3NvHOb1AnQntiyA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQiXEzzs44eot41NmB/19E+aqn1fafXwwM1LR+btiyA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQiXEzzo7G6JgyJVmftP70ZP1fZm8orXU6va0ZjKFk/eMX/26yPnT0aLKem5rCbvtlSa9JGpQ0EBE99WgKQP3VY8v+exHx8zq8DoAG4js7kIlawx6SNtjeart3tCfY7rXdZ7vvLb1Z49sBqFatu/FXRMQB2+dK2mj72YjYPPIJEbFc0nJJmuru8qsiADRUTVv2iDhQ3B6StFbSZfVoCkD9VR1225NsT3n7vqSPSdpVr8YA1Fctu/HTJa318PXMp0n6fkT8e126wknpuHReae25vzojue77v5Iei573wAvJ+lff93iyXmksPWXh03+SrM9447mqXztHVYc9Il6SdGkdewHQQAy9AZkg7EAmCDuQCcIOZIKwA5ngEtdTgLsmJOv7Pn52aS0G0qcov/KH56Tf/OqDyfIfnbk4WV/11JrS2pSO9D/XG89OS9bdkf4Z61BneXFoMLnueMSWHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTDDOfgrw+2cn6509vyitzb43fYlr99/+JFk/ck/6ElgfT4/jf+ZD15a/9gPpn6n+1KLNyfqGSy9J1qcuerG8WMNU06cqtuxAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmSCcfZ2UGHM96KVP03W9+2bW1o7dNsbyXVP//SkZD0G/idZH/qtDyTr3lI+lcDUpQPJdT+3fUuyvnpPetLgyR9dWFrrePzHyXXHI7bsQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kwtHE63anujs+4qub9n7jReecWcn6sbnlv/3+6He/lVz3unnpfx+DR44k62c+Pj1Zf+XIWaW1rR9+KLluJf87eCxZv2Hm79T0+o3k08pPcYmB9PkHKVtik47E4VFP3Ki4Zbe9wvYh27tGLOu2vdH288Vt+SwFANrCWHbjvyfpmncsu13SpoiYK2lT8RhAG6sY9ojYLOnwOxYvkbSquL9K0rX1bQtAvVV7bvz0iOgv7r8qqfSLm+1eSb2SdIYmVvl2AGpV89H4GD7CV3qULyKWR0RPRPR06fRa3w5AlaoN+0HbMySpuD1Uv5YANEK1YV8naVlxf5mkR+rTDoBGqfid3fZqSVdJOsf2fkl3Srpb0kO2b5a0T9L1jWwyd0cWnJusb/iHb5bW5q39fHLdh7f/Y7L+n8cuTtZvOuvJZH1yR/p361OePJ6eQ/3O2e07jl5JLWPp1aoY9ohYWlLi7BjgFMLpskAmCDuQCcIOZIKwA5kg7EAm+CnpU8CUf9uerH/g928trf30j/85ue6xofTPWE+fsjtZ79CEZD1l65snkvU7Z19W9Wvj3diyA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcbZTwFDx48n613TyuuDMZRcd2JHepy8Ur2S+4+U/8z1g5ecX9Nr4+SwZQcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBOMs48Ds5buLK3914vp/59fWf0vPY/J9z/9zjlBR9qVqKHe2LIDmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJxtnHg4jS0vGhruSqg/Fmst7p9Pag0vXyR2dOKq1N7EuuijqruGW3vcL2Idu7Riy7y/YB29uKv8WNbRNArcayG/89SaOdBnVPRCwo/tbXty0A9VYx7BGxWdLhJvQCoIFqOUB3q+0dxW7+2WVPst1ru89231tKfz8E0DjVhv3bki6StEBSv6Svlz0xIpZHRE9E9HTp9CrfDkCtqgp7RByMiMGIGJL0HUlMtwm0uarCbnvGiIfXiWsVgbZXcZzd9mpJV0k6x/Z+SXdKusr2Akkh6WVJn21ci6ioo7O0dGHXL5KrDlSYX33+yluS9a3L7knWpzxbfmx3MLkm6q1i2CNi6SiL72tALwAaiNNlgUwQdiAThB3IBGEHMkHYgUxwies48Oj+rYlq+SWmknTJEzcm63O+tS9Z71iW3l6s3nh/aW3ph5ck1x08eChZx8lhyw5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYYZz8FTNr83oa99gU37EnWB4bSF6L2nUhfIpuaEvqbTz2cXPcvLrgiWcfJYcsOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmGGdvAx2/eUmyvnL2ygqvcGZp5aL/uCm55pyhH1d47bS/+9RnkvUrHy6/nv3805ghqJnYsgOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kAnG2dvAwlXpa8rP6igfR5ekvSeOldYu/rO9yXWHklVJdrL8iZU/Stb7B14vrS37ZHo6aGt7so6TU3HLbnum7cds77G92/YXiuXdtjfafr64Pbvx7QKo1lh24wckfTEi5kv6bUm32J4v6XZJmyJirqRNxWMAbapi2COiPyKeKe6/JmmvpPMkLZG0qnjaKknXNqhHAHVwUt/ZbV8oaaGkLZKmR0R/UXpV0vSSdXol9UrSGZpYdaMAajPmo/G2J0taI+m2iDgyshYRISlGWy8ilkdET0T0dIkLH4BWGVPYbXdpOOgPRsTbPwl60PaMoj5DElNuAm2s4m68bUu6T9LeiPjGiNI6Scsk3V3cPtKQDjOwZv3lyfpXbtqRrM/pKt9j8hkV9qaOH0/Xnd4efO2H6WmX13z5qfKXHmJorZnG8p39ckk3Stppe1ux7A4Nh/wh2zdL2ifp+oZ0CKAuKoY9Ip6QVHZmxdX1bQdAo3C6LJAJwg5kgrADmSDsQCYIO5CJ8XOJa4VLMRWjnuDXFk68Jz0tciVd7iyt/evux5LrbjsxkKz//f7Fyfqsj5aPo0tSR2Kcf+hY+aW5qD+27EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZGL8jLO38Th6JfP++sVk/cVF5T/HLEkXdU0urXVWuB791zpPJOtb98xK1t/3yTnJ+rS125J1NA9bdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMjF+xtlPYSc+eEGy/vnfSF9TnjL0wynpJ3ypO13/XPr8hamrn0y/f/rV0URs2YFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyISjwnXgtmdKul/SdEkhaXlE3Gv7Lkl/LulnxVPviIj1qdea6u74iJn4FWiULbFJR+LwqJMojOWkmgFJX4yIZ2xPkbTV9saidk9EfK1ejQJonLHMz94vqb+4/5rtvZLOa3RjAOrrpL6z275Q0kJJW4pFt9reYXuF7bNL1um13We77y29WVu3AKo25rDbnixpjaTbIuKIpG9LukjSAg1v+b8+2noRsTwieiKip0vl834BaKwxhd12l4aD/mBEPCxJEXEwIgYjYkjSdyRd1rg2AdSqYthtW9J9kvZGxDdGLJ8x4mnXSdpV//YA1MtYjsZfLulGSTttbyuW3SFpqe0FGh6Oe1nSZxvQH4A6GcvR+CckjTZulxxTB9BeOIMOyARhBzJB2IFMEHYgE4QdyARhBzJxav2UtEe9cm/YKTxlM9AMbNmBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHchExZ+Sruub2T+TtG/EonMk/bxpDZycdu2tXfuS6K1a9eztgoh472iFpob9XW9u90VET8saSGjX3tq1L4neqtWs3tiNBzJB2IFMtDrsy1v8/int2lu79iXRW7Wa0ltLv7MDaJ5Wb9kBNAlhBzLRkrDbvsb2T2y/YPv2VvRQxvbLtnfa3ma7r8W9rLB9yPauEcu6bW+0/XxxO+ocey3q7S7bB4rPbpvtxS3qbabtx2zvsb3b9heK5S397BJ9NeVza/p3dtudkp6T9AeS9kt6WtLSiNjT1EZK2H5ZUk9EtPwEDNtXSnpd0v0R8cFi2VclHY6Iu4v/UZ4dEV9qk97ukvR6q6fxLmYrmjFymnFJ10r6U7Xws0v0db2a8Lm1Yst+maQXIuKliDgh6QeSlrSgj7YXEZslHX7H4iWSVhX3V2n4P5amK+mtLUREf0Q8U9x/TdLb04y39LNL9NUUrQj7eZJeGfF4v9prvveQtMH2Vtu9rW5mFNMjor+4/6qk6a1sZhQVp/FupndMM942n10105/XigN073ZFRHxI0iJJtxS7q20phr+DtdPY6Zim8W6WUaYZ/6VWfnbVTn9eq1aE/YCkmSMen18sawsRcaC4PSRprdpvKuqDb8+gW9weanE/v9RO03iPNs242uCza+X0560I+9OS5tqeZXuCpBskrWtBH+9ie1Jx4ES2J0n6mNpvKup1kpYV95dJeqSFvfyKdpnGu2yacbX4s2v59OcR0fQ/SYs1fET+RUlfbkUPJX3NlrS9+Nvd6t4krdbwbt1bGj62cbOk90jaJOl5ST+S1N1GvT0gaaekHRoO1owW9XaFhnfRd0jaVvwtbvVnl+irKZ8bp8sCmeAAHZAJwg5kgrADmSDsQCYIO5AJwg5kgrADmfg/ybRVUxz2L0MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "G.eval()\n",
        "\n",
        "z = torch.randn(1, n_noise).to(DEVICE)          # random noise vector 1x100\n",
        "\n",
        "label = 8\n",
        "label = torch.tensor([label])\n",
        "c = F.one_hot(label, num_classes=10).to(DEVICE) # one-hot encoding 1x10\n",
        "\n",
        "y_hat = G(z, c).view(1, 28, 28)\n",
        "plt.imshow(y_hat.squeeze().detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml53kkrizfVE",
        "outputId": "99f83b0e-3946-4f65-9759-ad0c79c6686f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7cb99a4940>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "G.eval()\n",
        "\n",
        "z = torch.randn(1, n_noise).to(DEVICE)          # random noise vector 1x100\n",
        "\n",
        "label = 8\n",
        "label = torch.tensor([label])\n",
        "c = F.one_hot(label, num_classes=10).to(DEVICE) # one-hot encoding 1x10\n",
        "\n",
        "y_hat = G(z, c).view(1, 28, 28)\n",
        "plt.imshow(y_hat.squeeze().detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLmx_IXGzfVE",
        "outputId": "db73bd2f-0c11-4e1f-e652-663fd32cb035"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7cb9cf69d0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "G.eval()\n",
        "\n",
        "z = torch.randn(1, n_noise).to(DEVICE)          # random noise vector 1x100\n",
        "\n",
        "label = 8\n",
        "label = torch.tensor([label])\n",
        "c = F.one_hot(label, num_classes=10).to(DEVICE) # one-hot encoding 1x10\n",
        "\n",
        "y_hat = G(z, c).view(1, 28, 28)\n",
        "plt.imshow(y_hat.squeeze().detach().cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--qQKUy5zfVE"
      },
      "source": [
        "And that's it! In this demo, we explored conditional GANs and looked a bit closely at the loss function used in GANs. Since GANs, there have been newer generative models such as diffusion models. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "95ee71ea249aa2e9e4602de52516e559983ad773b5ebbcec62edf843d39d54f2"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}